{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,f_classif,mutual_info_classif\n",
    "import jieba\n",
    "jieba.load_userdict('userword.txt')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "## 清理文本中的各种标点：\n",
    "def get_clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'^(1?[0-9]\\.?、?\\)?）?)?\\*?-?·?•?(\\\\t)?', '', text)\n",
    "    text = re.sub(r'[;；。]$', '', text)\n",
    "    text = re.sub(r'^\\s*', '', text)\n",
    "    text = text.replace(' ','')\n",
    "    return text\n",
    "\n",
    "## 把文本转化成句子列表：\n",
    "def text2sentences(text):\n",
    "    raw_data = []\n",
    "    for line in text.readlines():\n",
    "        raw_data.append(get_clean_text(line.decode('utf-8')))\n",
    "    raw_data = list(set(raw_data))\n",
    "    return raw_data\n",
    "\n",
    "###########seg_sentence function#####################################################\n",
    "# 创建停用词list\n",
    "def stopwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "# 对句子进行分词\n",
    "def seg_sentence(sentence):\n",
    "    sentence_seged = jieba.cut(sentence.strip())\n",
    "    stopwords = stopwordslist('stopwords.txt')  # 这里加载停用词的路径\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords:\n",
    "            outstr += word+'/'\n",
    "    outstr = outstr.split('/')\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_words_extraction(word_cuted, labels,score_func, func=TfidfVectorizer, **kwargs):\n",
    "    \"\"\"\n",
    "    传入文本和y值，用来构建模型和提取参数\n",
    "    :param word_cuted: dataframe 一列，每个值为分好词的文本，词汇以空格隔开\n",
    "    :param labels: numpy array of shape [n_samples]\n",
    "    :param keyword_ratio: 关键词提取比例\n",
    "    :param func: Vectorizer 的 方法，默认为tf-idf\n",
    "    :param kwargs: TfidfVectorizer 的 方法参数\n",
    "    \"\"\"\n",
    "    ############# 先通过tf-idf来获取文本代表词\n",
    "    vectorizer = func(**kwargs)\n",
    "    # 获取文本矩阵（词频，tf-idf等）\n",
    "    vec_matrix = vectorizer.fit_transform(word_cuted)\n",
    "    # 获取特征词\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "#     print(\"Orig_feature_names:\\n\",feature_names)\n",
    "#     print(\"-------------------\")\n",
    "    # 计算特征词数\n",
    "    # keyword_num = int(keyword_ratio * len(feature_names))\n",
    "#     keyword_num = int(keyword_ratio * len(labels))\n",
    "    keyword_num = 150\n",
    "    print('{}个特征词，{}个样本'.format(keyword_num, len(labels)))\n",
    "    if keyword_num == 0:\n",
    "        raise TrainException(\"特征词不足，请增加传入的数据量\")\n",
    "    # 根据具体方法，获取selector对象\n",
    "    if score_func == 'chi2':\n",
    "        selector = SelectKBest(chi2, k=keyword_num)\n",
    "    elif score_func == 'f_classif':\n",
    "        selector = SelectKBest(f_classif, k=keyword_num)\n",
    "    elif score_func == 'mutual_info_classif':\n",
    "        selector = SelectKBest(mutual_info_classif, k=keyword_num)\n",
    "    # 获取卡方矩阵\n",
    "    ch2_matrix = selector.fit_transform(vec_matrix, labels)\n",
    "    # 抽取特征词\n",
    "    feature_names = [feature_names[i] for i in selector.get_support(indices=True)]\n",
    "    print(\"用%s查到特征词：\\n\"%score_func,feature_names)\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_yes = 'C:/Users/x1c/Desktop/猎上顺丰简历项目/正负样本/产品经理合格.txt'\n",
    "f_no = 'C:/Users/x1c/Desktop/猎上顺丰简历项目/正负样本/产品经理不合格.txt'\n",
    "##### 把文本转化成干净的词列表：#############\n",
    "def from_text_to_clean_words(filepath):\n",
    "    f = open(filepath,'r',encoding='utf-8')\n",
    "    text_words = seg_sentence(get_clean_text(f.read()))\n",
    "    return text_words\n",
    "t_y = from_text_to_clean_words(f_yes)\n",
    "t_n = from_text_to_clean_words(f_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9829\n",
      "9829\n"
     ]
    }
   ],
   "source": [
    "####### 生成对应的标签列表，并将正负样本数据合并：##########\n",
    "yes_labels = list(np.ones(len(t_y)))\n",
    "no_labels = list(np.zeros(len(t_n)))\n",
    "text_cuted = t_y+t_n\n",
    "labels = yes_labels+no_labels\n",
    "print(len(text_cuted))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150个特征词，9829个样本\n",
      "用chi2查到特征词：\n",
      " ['04', '2017', '________________________________________', 'cn', 'erp', 'h5', 'http', 'https', 'it', 'k12', 'pc端', 'web', 'www', '一期', '一款', '七期', '下属', '专家', '业务', '业绩', '中移', '书写', '买金', '二期', '交互', '交互设计', '产品', '产品功能', '产品经理', '产品部', '人员', '人数', '信息化', '充值', '全网', '公司', '分析报告', '制定', '前台', '前端开发', '功能', '助教', '北京', '升级', '华润集团', '原因', '原型', '反馈', '后台', '国际', '地产', '地区', '场景', '基金', '增加', '大师', '学生', '官网', '实时', '客服', '宣传', '对接', '对象', '市场调研', '市场部', '建置', '德稻', '快速', '战略', '技能', '报告', '报表', '接入', '推荐', '提升', '搭建', '撰写', '操作', '支付', '改版', '效率', '教学', '数据', '数据分析', '方案', '方案设计', '时间', '明源', '期望', '期间', '架构', '梳理', '模块', '模式', '活动', '涵盖', '独立', '环节', '现有', '理财师', '用户', '电子商务', '监控', '直聘', '研发', '确保', '确认', '禅道', '程序', '立项', '简介', '简历', '管控', '精通', '系统', '线上', '经销商', '经验', '结算', '统一', '职务', '职责', '袋鼠', '视觉', '视频', '订单', '设计', '设计产品', '评估', '课程', '调研', '财务', '账号', '费用', '资金', '跨境电商', '跨部门', '输出', '运维', '部门', '金蝶', '金融', '集团', '需求', '页面', '项目', '风控', '高保真', '黄金', '黑产']\n",
      "-------------------\n",
      "150个特征词，9829个样本\n",
      "用f_classif查到特征词：\n",
      " ['04', '07', '09', '2017', '________________________________________', 'cn', 'erp', 'h5', 'http', 'https', 'it', 'k12', 'pc端', 'web', 'www', '一期', '一款', '七期', '下属', '专家', '业务', '业绩', '中移', '书写', '买金', '二期', '交互', '交互设计', '产品', '产品功能', '产品经理', '产品部', '人员', '人数', '信息化', '充值', '全网', '公司', '分析报告', '制定', '前台', '前端开发', '功能', '助教', '北京', '升级', '华润集团', '原因', '原型', '反馈', '后台', '国际', '地区', '场景', '基金', '增加', '大师', '学生', '官网', '实时', '客服', '宣传', '对接', '对象', '市场调研', '市场部', '建置', '德稻', '快速', '战略', '技能', '报告', '报表', '接入', '推荐', '提升', '搭建', '撰写', '操作', '支付', '改版', '效率', '教学', '数据', '数据分析', '方案', '方案设计', '时间', '明源', '期望', '期间', '架构', '梳理', '模块', '模式', '活动', '涵盖', '独立', '环节', '现有', '理财师', '用户', '电子商务', '监控', '直聘', '研发', '确保', '确认', '禅道', '程序', '立项', '简介', '简历', '管控', '精通', '系统', '线上', '经销商', '经验', '结算', '统一', '职务', '职责', '袋鼠', '视觉', '视频', '订单', '设计', '设计产品', '评估', '课程', '调研', '财务', '账号', '费用', '资金', '跨境电商', '跨部门', '输出', '运维', '部门', '金蝶', '金融', '集团', '需求', '页面', '项目', '风控', '黄金', '黑产']\n",
      "-------------------\n",
      "150个特征词，9829个样本\n",
      "用mutual_info_classif查到特征词：\n",
      " ['01', '02', '04', '05', '06', '07', '09', '2012', '2013', '2014', '2015', '2016', '2017', '31', '________________________________________', 'bi', 'erp', 'h5', 'http', 'https', 'it', 'k12', 'tms', 'web', 'www', '一期', '一款', '七期', '下属', '专家', '业务', '业绩', '中移', '书写', '买金', '交互', '交互设计', '产品', '产品经理', '人员', '人数', '供应商', '信息化', '充值', '全网', '公司', '内部', '分析报告', '制定', '前台', '前端开发', '功能', '助教', '北京', '升级', '华润集团', '原因', '原型', '反馈', '国际', '地区', '基金', '增加', '大师', '学生', '官网', '实时', '客服', '宣传', '对接', '对象', '市场调研', '市场部', '建置', '德稻', '战略', '技能', '报告', '报表', '拓展', '接入', '接口', '推荐', '搭建', '撰写', '操作', '支付', '支撑', '改版', '效率', '教学', '数据', '方案', '方案设计', '明源', '明源云', '期望', '期间', '架构', '梳理', '模块', '活动', '海普瑞', '独立', '环节', '理财师', '电子商务', '监控', '直聘', '确保', '禅道', '程序', '立项', '简介', '简历', '管控', '精通', '系统', '线上', '经销商', '结算', '统一', '网关', '职务', '职责', '袋鼠', '视觉', '视频', '订单', '设计', '设计产品', '评估', '课程', '财务', '财税', '账号', '费用', '资金', '跨境电商', '跨部门', '输出', '运维', '部门', '金蝶', '集团', '页面', '风控', '验证', '黄金', '黑产']\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "score_func_list = ['chi2','f_classif','mutual_info_classif']\n",
    "for func in score_func_list:\n",
    "    feature_words_extraction(text_cuted, labels, score_func=func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

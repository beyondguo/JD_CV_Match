{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\x1c\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.923 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('new_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本人 -- 擅长 -- 各种 -- 机器学习算法 -- 和 -- 深度学习 -- 算法 -- ， -- 对 -- 运筹与优化 -- 也 -- 颇 -- 有 -- 研究 -- ， -- 熟悉 -- 公司 -- 的 -- 战略规划 -- ， -- 经常 -- 为 -- 公司 -- 制定 -- 发展战略\n"
     ]
    }
   ],
   "source": [
    "s = '本人擅长各种机器学习算法和深度学习算法，对运筹与优化也颇有研究，熟悉公司的战略规划，经常为公司制定发展战略'\n",
    "print(' -- '.join(jieba.lcut(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snownlp import SnowNLP\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"wiki+meitanbaidu.txt\",encoding='utf-8')\n",
    "t1 = time.time()\n",
    "text = file.read()\n",
    "print('字数：',len(text))\n",
    "text = SnowNLP(text)\n",
    "ss = text.sentences\n",
    "print('句子数：',len(ss))\n",
    "t2 = time.time()\n",
    "print(\"文本分句总耗时：\",t2-t1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_sen = []\n",
    "t3 = time.time()\n",
    "for each in ss:\n",
    "    split_sen.append(jieba.lcut(each))\n",
    "t4 = time.time()\n",
    "print(len(split_sen))\n",
    "print(\"分词样例：\\n\",split_sen[0:3])\n",
    "print(\"分词总耗时：\",t4-t3,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5 = time.time()\n",
    "wv_model = Word2Vec(split_sen,min_count=3,window=5,size=250,sg=1)\n",
    "t6 = time.time()\n",
    "print('训练词向量模型用时：',t6-t5,'s.')\n",
    "wv_model.save('models/wikibaikewv250')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
